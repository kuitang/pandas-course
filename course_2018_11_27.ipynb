{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Python, Pandas, and Jupyter Notebook\n",
    "\n",
    "JupyterLab is a convenient interface for interactive coding.\n",
    "\n",
    "It allows you to mix text (including $\\LaTeX$ for math, if you're into that), code, results of the code, graphics, and even interactive widgets.\n",
    "\n",
    "![PyData Stack](http://chris35wills.github.io/courses/pydata_stack.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using the Notebook [0:01]\n",
    "\n",
    "One difference from regular Python is that whereas regular Python (inculding on Codecademy) will not display any output until you type `print`, Jupyter notebook will output the last _expression_ of each cell.\n",
    "\n",
    "Most code that calculates a value is an expression. Assignments (=) are not expressions.\n",
    "\n",
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"hello\" + \" \" + \"world\" + \" \" + str(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the toolbar to add and edit cells. You can run a cell by pressing Ctrl-Enter.\n",
    "\n",
    "The drop-down selector for \"Markdown\" means text. \"Code\" is code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Looking at our Data [0:02]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library we use is called Pandas, short for \"Python data analysis.\"\n",
    "\n",
    "We usually shorten it to `pd`, so we can call its method using `pd.` instead of `pandas.`.\n",
    "\n",
    "You can read its documentation here: http://pandas.pydata.org/pandas-docs/stable/. <-- Keep this website open as you play with Pandas. It is the official documentation for the Pandas library and is comprehensive. A Google search will help you find examples for how to use code, but the official documentation will give you the straight dope on how everything works, which is important because Pandas is a huge library with many details.\n",
    "\n",
    "We will use _real_, de-identified physiological data from ICU patients from https://physionet.org/challenge/2012/. <-- Open this to see the data dictionary. Always get a data dictionary and avoid guessing what numbers mean when you can (but many times you can't...)\n",
    "\n",
    "Pandas can read files directly from URLs, so we don't need to download and upload this file to our laptops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This lets us use the library pandas shortened as pd\n",
    "import pandas as pd\n",
    "#  This creates a data frame called 'df' with values loaded from online\n",
    "df = pd.read_csv(\"https://physionet.org/challenge/2012/set-a/132551.txt\")\n",
    "\n",
    "\n",
    "# Pandas uses Matplotlib for plotting. This line below is special IPython Notebook syntax (magic) to show plots in the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter notebook automatically prints the DataFrame as an HTML table. Compare this to viewing the file in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your tables are much bigger than this one, printing it all out may be slow. You can instead do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows first 5 entries\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows last 5 entries\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame consists of multiple columns and rows. We can see the row labels with the index attribute.  We can see which columns the data frame currently has using the columns attribute (notice no parentheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index #row labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns #column labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the data frame has three columns labeled 'Time', 'Parameter', and 'Value'.  While the rows are labeled 0 to 672.  \n",
    "\n",
    "We can pull specific values from the data frame by selecting the row and column accordingly using the loc (location) and iloc (indexed location) meathods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[4,'Parameter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[4,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select individual rows by only entering the row into loc or iloc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you can call a column using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Parameter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that ':' in the row stands for 'everything'.  A useful shortcut is to just call into the data frame like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Parameter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column is a a new type: Series. In fact, all Series have the same type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['Parameter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But different Series can contain different types of data. The type of the data contained inside the Series is the `.dtype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Parameter'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``'O'`` means \"Python object\", but in general, it usually means string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Value'].dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**: Select the Time column.\n",
    "\n",
    "What is the type of the Time column?\n",
    "\n",
    "What type of data does the Time column contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Cleaning up Datetimes [0:10]\n",
    "\n",
    "**What did we notice about the Time column?**\n",
    "\n",
    "Cleaning up datetimes is a common bane of data analysis. Fortunately, Pandas was developed by a trader, so it has excellent support for time series data. Physiological data are also time series data.\n",
    "\n",
    "How do we interpret the numbers in Time? Don't guess! Read the data dictionary:\n",
    "\n",
    "> Each observation has an associated time-stamp indicating the elapsed time of the observation since ICU admission in each case, in hours and minutes. Thus, for example, a time stamp of 35:19 means that the associated observation was made 35 hours and 19 minutes after the patient was admitted to the ICU.\n",
    "\n",
    "So Time is not an absolute datetime, but rather a _time delta_ relative to the start of the patient's ICU stay.\n",
    "\n",
    "Pandas has a special data type to represent this phenomenon: `Timedelta`. (`DateTime` is for absolute datetimes, i.e. '2018-11-29 11:00:00').  You can easily convert a column to a timedelta type using pd.to_timedelta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_timedelta(df['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just try adding :00 to the end of everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_timedelta(df['Time'] + \":00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked!\n",
    "\n",
    "However if we look at the data frame the values remain unchanged..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note the dataframe is unchanged!\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the data frame we have to reassign the values of the column.\n",
    "\n",
    "Before we do that though let's save our results to a new DataFrame.\n",
    "\n",
    "In general, I try to avoid overwriting DataFrames. Instead, I create new ones as as I go. This ensures that I can always backtrack to an earlier stage of the data manipulation if something didn't work or to explore something else, without having to restart the program from scratch.\n",
    "\n",
    "Name variables descriptively, **NOT** df2, df3, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_td = df.copy()\n",
    "\n",
    "#we assign the column to the data frame\n",
    "df_td['Time'] = pd.to_timedelta(df_td['Time'] + \":00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with time series data in Pandas, we must set the _index_ to be the time to enable Pandas to be smart about datetime.\n",
    "\n",
    "One thing Pandas can do intelligently with a DateTime or Timedelta index is plotting, which we will explore later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_td_ix = df_td.set_index('Time')\n",
    "df_td_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_td_ix.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the rows are labeled differently and the data frame has one less column(which will change iloc).  As well as loc has to now take one of the earlier selected values now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_td_ix.iloc[4,0] # vs df.iloc[4,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_td_ix.loc['00:05:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Queries [0:20]\n",
    "\n",
    "**What are the different kinds of Parameters?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like you can call methods on strings, you can call methods on columns (Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_td_ix['Parameter'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that ``df['Parameter']`` is a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_td_ix['Parameter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that since we set `df_td_ix` to have a Timedelta index, every column we extract from `df_td_ix` will now have the SAME Timedelta index.\n",
    "\n",
    "Compare to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Parameter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which only shows the row number, which is less useful than directly showing the Timedelta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many measurements of each do we have?**\n",
    "\n",
    "You can write SQL-like code in Pandas. It will not be as elegant as SQL (if you think SQL is elegant, that is), but in addition to what you can do in SQL, you can do anything else you want in Python.\n",
    "\n",
    "        select Parameter, count(*) from df group by Parameter order by count(*) desc\n",
    "        \n",
    "        \n",
    "If you are interested in more advanced operations, take a look here: https://medium.com/jbennetcodes/how-to-rewrite-your-sql-queries-in-pandas-and-more-149d341fc53e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This counts all the occurences of each parameter type in the Parameter column and sorts it. \n",
    "df_td_ix.groupby('Parameter')['Parameter'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can save this to a new variable.\n",
    "\n",
    "Remember that whie in regular Python no output is shown unless you use ``print``, Jupyter Notebook will by default print the last line in each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_td_ix.groupby('Parameter')['Parameter'].count().sort_values(ascending=False) # this doesn't print anything\n",
    "counts # but this does\n",
    "\n",
    "# If we uncomment the line below, then we no longer see counts, but we will see 2.\n",
    "# 1 + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Boolean Series and Selections [0:25]\n",
    "\n",
    "We can do logical expressions on columns.\n",
    "\n",
    "Notice how typing ``counts > 10`` evaluated _every_ entry of ``counts``. This is known as a _vectorized operation_. This is because ``counts`` behaves like a mathematical vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_params = counts > 10\n",
    "frequent_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a Series contains only bool elements, we can use it as an index using the ``.loc`` syntax: (loc = locate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.loc[frequent_params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select the first and last elements from a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_rows = df_td_ix['Parameter'] == 'HR'\n",
    "hr_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of `hr_rows` equals the number of rows of `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hr_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_td_ix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames have two dimensions. We can select rows or columns or both.\n",
    "\n",
    "Remember `:` means \"select everything in this dimension\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_td_ix.loc[:, 'Value'] # Equivalent to df_td_ix['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_df_td_ix = df_td_ix.loc[hr_rows, :]\n",
    "hr_df_td_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#alternatively you can do it all in one go\n",
    "df_td_ix.loc[df_td_ix['Parameter'] == 'HR',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_df_td_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_rows.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can treat `bool` Series as Series of 1s and 0s.\n",
    "\n",
    "**EXERCISE**: Explain the above two statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE**: Pick a different parameter, and select all the rows of `df` corresponding to that parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plotting and Pivoting [0:35]\n",
    "\n",
    "Recall that. Pandas actually uses Matplotlib under the hood for plotting. If you ran `%matplotlib inlne`, you can just use the `.plot()` methods, which do some of the work for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can see the heart rate over time\n",
    "hr_df_td_ix['Value'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can see the frequency of different heart rate ranges over the different measurements\n",
    "hr_df_td_ix['Value'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The long format is not very convenient. Let's pivot it to wide format. This is like a PivotTable in Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df_td_ix.pivot(columns='Parameter', values='Value')\n",
    "df_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RecordID is a unique number that identifies each visit. Since we only loaded the data for one visit, let's get rid of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide['RecordID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_wide['RecordID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivoting revealed the gaps in our data: each cell represents a measurement of some value at some time. If a parameter, e.g. 'Age' is not measured at '1 days 14:18:00', then it shows up a `NaN` (like `NA` in R).\n",
    "\n",
    "Usually for physiological data, we forward-fill:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_filled = df_wide.ffill()\n",
    "df_wide_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot _everything_!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_filled.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, that wasn't very useful because the different data are on different scales.\n",
    "\n",
    "One useful Pandas features is to compute summary statistics of everything at once. This method by default will ignore NaNs, which is what we want, since the NaNs are holes in the data.\n",
    "\n",
    "**CAUTION**: To compute correct summary statistics, we must use `df_wide`, the DataFrame with \"holes\", NOT `df_wide_filled`. We don't want the filled-in data to count multiple times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df_wide.describe()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Pandas will hide extra columns. If we want to see EVERYTHING, we need to set an option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arterial blood pressures are on a similar scale, so let's just plot those:\n",
    "\n",
    "Clinical reference:\n",
    "- MAP = mean arterial pressure\n",
    "- DiasABP = diastolic arterial blood pressure\n",
    "- SysABP = systolic arterial blood pressure\n",
    "- NI = non-invasive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[['MAP', 'DiasABP', 'SysABP', 'NIMAP', 'NIDiasABP', 'NISysABP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_filled[['MAP', 'DiasABP', 'SysABP', 'NIMAP', 'NIDiasABP', 'NISysABP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_filled[['NIDiasABP', 'NIMAP', 'NISysABP', 'DiasABP', 'MAP', 'SysABP']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the mean pressures fall between the diastolic and systolic. Also, the noninvasive pressures are usually lower than the corresponding invasive pressures. (Noninvasive is measured with a cuff; invasive is measured with a balloon inserted into the artery.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_filled[['NIDiasABP', 'NIMAP', 'NISysABP']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_filled[['DiasABP', 'MAP', 'SysABP']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the noninvasive measurements differs quite a bit from the invasive ones... I wonder which one is more accurate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another fun plot is a scatter matrix: a grid of scatterplots for every possible pair of columns. Let's try one with the blood pressures, and throw in heartrate for good measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(df_wide_filled[['HR', 'NIDiasABP', 'NIMAP', 'NISysABP', 'DiasABP', 'MAP', 'SysABP']], figsize=(12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that heartrate has some correlation with each blood pressure measurement. Also, the blood pressures are highly correlated for the same level of invasiveness, but not across the two levels of invasiveness. \n",
    "\n",
    "This is a problem. Noninvasive blood pressures should be highly correlated with invasive blood pressures. Assuming that our invasive measurements are correct (which is most likely the case), this may mean that our noninvasive measurements (cuffs) are inaccurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transforming Data, Writing Output [0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull out just the mean and standard deviations for each parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.loc['mean', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.loc['std', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(summary.loc['mean', :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that if we select a row from a DataFrame, we get a Series indexed by the columns of the DataFrame.\n",
    "\n",
    "Recall again that if we select a column from a DataFrame, we get a Series indexed by the rows of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.loc[:, 'MAP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `summary.loc['mean', :]` and `summary.loc['std', :]` are indexed by the columns of `df_wide_filled`, Pandas is smart enough to figure out what we mean when we type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_filled - summary.loc['mean', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the computation for one cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_filled.loc['0 days 00:50:00', 'BUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.loc['mean', 'BUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_filled.loc['0 days 00:50:00', 'BUN'] - summary.loc['mean', 'BUN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing, we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_filled_zscores = (df_wide_filled - summary.loc['mean', :]) / summary.loc['std', :]\n",
    "df_wide_filled_zscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this generated some extra NaNs (holes). Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.loc[['count', 'std'], ['ALP', 'ALT', 'AST', 'Age', 'Albumin']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only ever have one measurement of these variables. The standard deviation of a sample of size 1 is undefined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's save our work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide_filled_zscores.to_csv('filled_zscores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
